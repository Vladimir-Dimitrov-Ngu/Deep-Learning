{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from sklearn.datasets import load_boston\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:05<00:00, 1807026.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2305324.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./mnist/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Скачаем данные \n",
    "mnist_train = torchvision.datasets.MNIST(\n",
    "    \"./mnist/\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ") \n",
    "mnist_val = torchvision.datasets.MNIST(\n",
    "    \"./mnist/\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# так как это уже унаследованный от Dataset класс, его можно сразу обернуть в даталоадер\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_train, \n",
    "    batch_size=4, \n",
    "    shuffle=True, \n",
    "    num_workers=1\n",
    ") \n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    mnist_val, \n",
    "    batch_size=4, \n",
    "    shuffle=True, \n",
    "    num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Посмотрим с чем работаем\n",
    "for i in [0, 1]:\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.imshow(mnist_train[i][0].squeeze(0).numpy().reshape([28, 28]))\n",
    "    plt.title(str(mnist_train[i][1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Flatten(),             # превращаем картинку 28х28 в вектор размером 784\n",
    "    nn.Linear(28 * 28, 128),  # линейный слой, преобразующий вектор размера 784 в вектор размера 128\n",
    "    nn.ReLU(),                # нелинейность\n",
    "    nn.Linear(128, 10),       # линейный слой, преобразующий вектор размера 128 в вектор размера 10\n",
    ")\n",
    "\n",
    "# создаем оптимизатор, который будет обновлять веса модели\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры выглядят следующем образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0265,  0.0292, -0.0209,  ...,  0.0295,  0.0245,  0.0309],\n",
       "          [ 0.0139, -0.0144, -0.0306,  ...,  0.0193,  0.0201, -0.0116],\n",
       "          [-0.0220,  0.0235,  0.0298,  ...,  0.0227, -0.0287, -0.0120],\n",
       "          ...,\n",
       "          [ 0.0143, -0.0029,  0.0271,  ..., -0.0348,  0.0111, -0.0291],\n",
       "          [ 0.0267,  0.0087,  0.0030,  ..., -0.0221, -0.0210, -0.0062],\n",
       "          [-0.0309, -0.0119,  0.0087,  ..., -0.0146,  0.0144, -0.0110]],\n",
       "         requires_grad=True)),\n",
       " ('1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0354,  0.0328, -0.0137, -0.0285,  0.0280,  0.0169, -0.0243, -0.0066,\n",
       "           0.0086, -0.0216,  0.0301,  0.0040, -0.0323,  0.0255, -0.0107, -0.0074,\n",
       "          -0.0128,  0.0117, -0.0033,  0.0275, -0.0228,  0.0240,  0.0280, -0.0104,\n",
       "          -0.0049,  0.0026,  0.0345,  0.0224, -0.0113, -0.0046, -0.0032,  0.0064,\n",
       "          -0.0259, -0.0167, -0.0300, -0.0294, -0.0001,  0.0021, -0.0208, -0.0233,\n",
       "           0.0295, -0.0035, -0.0264, -0.0275, -0.0194,  0.0035, -0.0045, -0.0297,\n",
       "           0.0117, -0.0146, -0.0290, -0.0040,  0.0144, -0.0134, -0.0348, -0.0210,\n",
       "          -0.0052, -0.0319, -0.0299,  0.0005,  0.0331,  0.0200,  0.0227,  0.0269,\n",
       "           0.0116,  0.0173,  0.0321, -0.0057,  0.0065,  0.0146, -0.0165, -0.0192,\n",
       "           0.0104,  0.0062,  0.0040,  0.0256,  0.0330, -0.0253,  0.0114, -0.0222,\n",
       "           0.0299, -0.0343, -0.0320, -0.0197,  0.0094,  0.0119,  0.0232,  0.0284,\n",
       "          -0.0283, -0.0046,  0.0119, -0.0164, -0.0218, -0.0342,  0.0337,  0.0281,\n",
       "          -0.0208, -0.0102, -0.0318,  0.0027,  0.0194,  0.0218, -0.0198, -0.0333,\n",
       "          -0.0049, -0.0036, -0.0323, -0.0246,  0.0039,  0.0079, -0.0099,  0.0222,\n",
       "           0.0324,  0.0093,  0.0244, -0.0250, -0.0195,  0.0103, -0.0290,  0.0335,\n",
       "          -0.0026,  0.0050,  0.0191, -0.0160, -0.0035, -0.0292,  0.0106, -0.0248],\n",
       "         requires_grad=True)),\n",
       " ('3.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0162, -0.0062,  0.0869,  ...,  0.0850,  0.0564,  0.0418],\n",
       "          [-0.0573, -0.0344,  0.0123,  ..., -0.0463,  0.0615,  0.0536],\n",
       "          [-0.0077,  0.0574, -0.0267,  ...,  0.0553, -0.0034,  0.0152],\n",
       "          ...,\n",
       "          [-0.0346, -0.0778,  0.0151,  ..., -0.0075, -0.0081,  0.0831],\n",
       "          [-0.0374, -0.0740, -0.0057,  ..., -0.0602, -0.0731, -0.0545],\n",
       "          [ 0.0716, -0.0872,  0.0368,  ...,  0.0247,  0.0463, -0.0750]],\n",
       "         requires_grad=True)),\n",
       " ('3.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0036,  0.0373, -0.0789,  0.0779,  0.0126,  0.0044, -0.0719, -0.0037,\n",
       "          -0.0545,  0.0782], requires_grad=True))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in model.named_parameters()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для красивых метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb --upgrade --quiet\n",
    "import wandb\n",
    "\n",
    "# логинимся в своего пользователя (предварительно нужно ввести ключ из настроек с wandb.ai через консоль)\n",
    "wandb.login()\n",
    "# инициализируем проект\n",
    "wandb.init(project=\"pytorch-demo\")\n",
    "# сохраняем параметры сетки в wandb + просим следить за градиентами сетки\n",
    "wandb.watch(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7fee3af3f04572a1874472d133ee2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a654d3300c544239964a48280707a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.11758233606815338, accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf3e21eca794439917faf1ab39a1928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c6e5aca78646c88df5bbf655fef8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bb314dd5864a2eaa62ad4216ea4923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.08408485352993011, accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e53c87485c4818aaf5cad6d4ca5353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340b5a45f4a14146adc5b5b399bf5343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea1d955412a44f980f138b38478a4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.080023854970932, accuracy: 0.9772\n"
     ]
    }
   ],
   "source": [
    "# всего у нас будет 5 эпох (5 раз подряд пройдемся по всем батчам из трейна)\n",
    "for epoch in range(5):\n",
    "    for x_train, y_train in tqdm(train_dataloader):    # берем батч из трейн лоадера\n",
    "        y_pred = model(x_train)                        # делаем предсказания\n",
    "        loss = F.cross_entropy(y_pred, y_train)        # считаем лосс\n",
    "        loss.backward()                                # считаем градиенты обратным проходом\n",
    "        optimizer.step()                               # обновляем параметры сети\n",
    "        optimizer.zero_grad()                          # обнуляем посчитанные градиенты параметров\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        val_loss = []                                  # сюда будем складывать **средний по бачу** лосс\n",
    "        val_accuracy = []\n",
    "        with torch.no_grad():                          # на валидации запрещаем фреймворку считать градиенты по параметрам\n",
    "            for x_val, y_val in tqdm(val_dataloader):  # берем батч из вал лоадера\n",
    "                y_pred = model(x_val)                  # делаем предсказания\n",
    "                loss = F.cross_entropy(y_pred, y_val)  # считаем лосс\n",
    "                val_loss.append(loss.numpy())          # добавляем в массив \n",
    "                val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "          \n",
    "        # скидываем метрики на wandb и автоматом смотрим на графики\n",
    "        #wandb.log({\"mean val loss\": np.mean(val_loss),\n",
    "        #           \"mean val accuracy\": np.mean(val_accuracy)})\n",
    "        \n",
    "        # печатаем метрики\n",
    "        print(f\"Epoch: {epoch}, loss: {np.mean(val_loss)}, accuracy: {np.mean(val_accuracy)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
